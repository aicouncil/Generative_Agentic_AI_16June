The meeting on August 1, 2025, at 19:32 GMT+05:30, involved AI Council, Pritam Kusiyait, and Shivam Singh Patel. The discussion centered on creating and troubleshooting AI agents, configuring prompts, and managing API key issues. They also explored various LLM models like Gemini, GPT, and Groq, comparing their costs, performance, and billing. A key topic was the distinction between online and offline Llama models, with a practical focus on using local LLMs via Olama.

Key discussion points included:

  * **Agent Creation and Prompt Configuration**: AI Council demonstrated creating a "storyteller" agent for kids' stories (8-12 years, around 500 words) and a "title generator" to create 10 titles from the story output. A supervisor prompt was configured to manage the workflow between these two.
  * **Troubleshooting Agent Loops**: The agent repeatedly looped tasks. This was resolved by modifying the title generator prompt to terminate after 10 titles and setting maximum iterations to two for both the storyteller and title generator.
  * **Resolving API Key and Prompt Issues**: Pritam Kusiyait faced an error with the agent not running. AI Council guided them through checking and creating a new Gemini API key and ensured consistency in worker names in the prompts (e.g., "storyteller" with and without spaces).
  * **Exploring LLM Models and Billing**:
      * **Gemini**: Discussed its free version's instability and the Pro version obtained through Google subscriptions.
      * **GPT**: Introduced as a more stable option for agents. AI Council demonstrated obtaining an API key from OpenAI, emphasizing that it can only be copied once. Billing for GPT was explained, including adding payment methods and the cost implications of models like 4.1 mini and 4.1 nano. New OpenAI accounts typically receive a $5 free credit, and AI Council advised against enabling automatic recharge to control spending. They tested GPT with 4.1 nano for lower cost (though less creative results) and then 4.1 mini for better stability and title generation.
      * **Groq**: Introduced as an option for utilizing open-source models like Llama, Compound, and Deepseek. AI Council demonstrated finding and using the Groq API key, noting its free access up to a certain extent. Initial testing with a Llama model on Groq did not work, highlighting the need to identify functional free models.
  * **Online vs. Offline Llama Models**: AI Council clarified that online access often uses APIs like Groq, while offline usage involves installing models directly onto a system via tools like Olama.
  * **Olama Installation and Usage**: Instructions were provided for using Olama to install open-source models offline from olama.com. This enables offline functionality without an internet connection and does not require account creation for download and use.
  * **LLM Model Characteristics and RAG**: AI Council explained that LLMs inherently contain trained data and algorithms, not requiring internet access unless additional features are integrated. They also defined Retrieval Augmented Generation (RAG) as augmenting an LLM with specific user data (e.g., PDFs, text, or specific internet sources) to enhance output.
  * **Downloading and Managing Offline Models**: AI Council showed how to download and install specific Llama models using Olama, noting model size variations (e.g., DeepSeek is 44GB). They advised model selection based on system space, explaining that local installation avoids server busyness issues, though processing speed depends on the local system's CPU or GPU.
  * **Configuring and Running Offline Models**: The process for running an installed Llama model offline was detailed, involving the `olama serve` command to activate a local server and configuring a chat interface with the local IP address and model name. Offline processing might be slower due to reliance on the local system's CPU but ensures consistent operation.

The suggested next step is for AI Council to provide the process to fix issues where the model is not running in the next session.
